---
title: "Regression methods"
subtitle: "bayesics Package Version `r packageVersion('bayesics')`"
format: 
  html:
    toc: true
    html-math-method: mathjax
    self-contained: true
vignette: >
  %\VignetteIndexEntry{Regression-methods}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
bibliography: bibliography.bib
---

```{r, include = FALSE}

knitr::opts_chunk$set(
  strip.white = FALSE,
  collapse = TRUE,
  comment = "#>",
  warning = FALSE,
  message = FALSE,
  fig.width = 7,
  fig.height = 4,
  fig.align = "center",
  cache = TRUE,
  results = "verbatim"
)

options(knitr.table.format = "html")
library(bayesics)
set.seed(2025)
```




# Linear regression with `lm_b` {#sec-lm_b}


## Statistical Model {#sec-lm_model}
Linear regression is the bread and butter of the practicing statistician.  Mathematically, the model is given by
$$
\begin{aligned}
  y & = X\beta + \epsilon, \\
  \epsilon & \sim N(0,\sigma^2 I).
\end{aligned}
$$

While an improper prior of the form 
$$
\pi(\beta,\sigma^2) \propto \frac{1}{\sigma^2}
$$
can be used, it is recommended to use a proper prior.  In `bayesics` we implement a normal-inverse gamma prior:
$$
\begin{aligned}
  \beta|\sigma^2 & \sim N(\mu,\sigma^2 V^{-1}),\\
  \sigma^2 & \sim \Gamma^{-1}(a/2,b/2).
\end{aligned}
$$

The resulting posterior (for both proper and improper priors) is of the same form:
$$
\begin{aligned}
  \beta|y,\sigma^2 & \sim N(\tilde\mu,\sigma^2 \widetilde{V}^{-1}),\\
  \sigma^2|y & \sim \Gamma^{-1}(\tilde a/2,\tilde b/2).
\end{aligned}
$$


In `lm_b` the mapping of parameters to arguments is given by:

<table markdown="1" style="border-collapse: collapse; width: 60%; text-align: center;">
  <thead>
    <tr style="border-top: 1px solid lightgray;">
      <th style="border-right: 1px solid lightgray;">Parameter</th>
      <th> bayesics argument</th>
    </tr>
  </thead>
  <tbody>
     <tr style="border-bottom: 1px solid lightgray;border-top: 1px solid lightgray;">
      <th colspan="2">Prior Parameters</th>
    </tr>
   <tr>
      <td style="border-right: 1px solid lightgray;">$\mu$</td>
      <td><code>prior_beta_mean</code></td>
    </tr>
    <tr>
      <td style="border-right: 1px solid lightgray;">$V$</td>
      <td><code>prior_beta_precision</code></td>
    </tr>
    <tr>
    </tr>
    <tr>
      <td style="border-right: 1px solid lightgray;">$a$</td>
      <td><code>prior_var_shape</code></td>
    </tr>
    <tr>
      <td style="border-right: 1px solid lightgray;">$b$</td>
      <td><code>prior_var_rate</code></td>
    </tr>
    <thead>
      <th colspan="2" style="border-bottom: 1px solid lightgray;border-top: 1px solid lightgray;"> Posterior parameters </th>
    </thead>
    <tr>
      <td style="border-right: 1px solid lightgray;">$\tilde\mu$</td>
      <td><code>object\$posterior_parameters\$mu_tilde</code></td>
    </tr>
    <tr>
      <td style="border-right: 1px solid lightgray;">$\widetilde V$</td>
      <td><code>object\$posterior_parameters\$V_tilde</code></td>
    </tr>
    <tr>
      <td style="border-right: 1px solid lightgray;">$\tilde a$</td>
      <td><code>object\$posterior_parameters\$a_tilde</code></td>
    </tr>
    <tr style="border-bottom: 1px solid lightgray;">
      <td style="border-right: 1px solid lightgray;">$\tilde b$</td>
      <td><code>object\$posterior_parameters\$b_tilde</code></td>
    </tr>
  </tbody>
</table>


## Default priors {#sec-lm_priors}
### $\beta$
The default prior is Zellner's $g$ prior [@zellner1986assessing], which aims to preserve the same prior beliefs under any scale transformation of the covariates (e.g., if we measure distance in miles vs. in km, our prior beliefs will be coherent with each other).  This prior is:
$$
  \beta|\sigma^2 \sim N(0,\sigma^2g(X'X)^{-1})
$$
for $g=n$ by default as is customary for a reference prior, else a user-supplied $g$ (via the `zellner_g` argument).  I.e., $V = X'X$.


The other built-in prior is if `prior="conjugate"`.  The prior precision matrix $V$ is set to be a diagonal matrix, with notions from standardized regression motivating the diagonal elements.  In standardized regression, we consider the following:
$$
  \begin{aligned}
    	y_i^*& = \frac{y_i-\bar y}{s_y}, \\
    	X_{ij}^*& = \frac{X_{ij}-\bar X_j}{s_j}, \\
	\end{aligned}
$$
Note that there is a simple 1-1 transformation to get from the standardized regression coefficients ($\beta^*$) back to the coefficients on the original scale:
$$
\begin{aligned}
	\beta_j &= \frac{s_y}{s_j}\beta_j^* \\
	\beta_0 &= \bar y - \beta_1\bar X_1 - \ldots - \beta_{p-1}\bar X_{p-1}
\end{aligned}
$$
Here is the underlying principle to set the prior hyperparameters: *If we feel 95% sure that a standard deviation change in* $X_{ij}$ *would not lead to more than a 5 SD increase in* $y$, *i.e.*, $1.96 \cdot SD(\beta_j^*) \approx 2\cdot SD(\beta_j^*) = 5$, then we could set
$$
\begin{aligned}
  \beta^*_j &\sim N(0,25/4), \\
  \Rightarrow \beta_{-1} & \sim N\left(0,\frac{25}{4} \text{Diag}\left(\frac{s^2_y}{s^2_j}\right)\right)
\end{aligned}
$$
where $s_y$ is the standard deviation of $y$, $s_j$ is the standard deviation of the $j^{th}$ covariate, $\beta_{-1}$ is the vector of regression coefficients sans the intercept. We can complete $V$ by setting a flat prior on the intercept such that the prior variance is $\frac{25}{4}s_y^2$.


### $\sigma^2$
By default, the values of $a$ and $b$ are set to be small (0.001) in order to provide a very flat prior on $\sigma^2$.  However, we can find a better prior using the `bayesics` function `find_invgamma_parms()`.

A reasonable approach to building a good prior on $\sigma^2$ via a peak at the data would be to look at the sample variance of the response variable, and then build a prior around that.  If a priori we are 80% sure the covariates will explain between 10% and 90% of the variation in y, then the prior on $\sigma^2$ ought to have 0.8 of its probability mass between $0.1s^2_y$ and $0.9s^2_y$.  This can be accomplished via the `find_invgamma_parms` function.


## `lm_b` Example
As an example, we'll look at the air quality dataset:
```{r}
library(dplyr)
library(bayesics)
data("airquality",package = "datasets")

aq =
  airquality |>
  mutate(
    # Use log(ozone) as response variable
    log_ozone = log(Ozone),
    # Compute the day of the year
    year_day =
      cumsum(c(0,31,28,31,30,31,30,31,31,30,31,30))[Month] + Day,
    # Turn month into a factor variable
    Month = factor(Month)) |>
  na.omit()
```
The outcome is the ozone in ppb, and the covariates include the solor radiation (Langley), wind speed (MPH), temperature (F), and day of the year.


We could use the default $\Gamma(0.001/2,0.001/2)$ flat prior on $\sigma^2$, but instead let's find a reasonable concentrated prior.
```{r}
s2_y = var(aq$log_ozone)
a_and_b =
  find_invgamma_parms(lower_quantile = 0.1 * s2_y,
                      upper_quantile = 0.9 * s2_y,
                      probability = 0.8,
                      plot = FALSE)
a_and_b
# or equivalently:
find_invgamma_parms(response_variance = s2_y,
                    lower_R2 = 0.1,
                    upper_R2 = 0.9,
                    probability = 0.8)
# Check, since a solution is not at all guaranteed to exist:
extraDistr::pinvgamma(0.1 * s2_y,
                      0.5 * a_and_b[1],
                      0.5 * a_and_b[2])
extraDistr::pinvgamma(0.9 * s2_y,
                      0.5 * a_and_b[1],
                      0.5 * a_and_b[2],
                      lower.tail = FALSE)
```

Now let's use `lm_b` to fit the linear regression model.  We can use diagnostic plots to see that we really do need to use the log of Ozone as the response variable for our model assumptions to hold (mostly).

```{r}
bad_fit =
  lm_b(Ozone ~ Solar.R + Wind + Temp + year_day,
       data = aq)
plot(bad_fit,
     type = "dx")
```

Now let's use log(Ozone) with a Zellner's g prior and our concentrated prior on $\sigma^2$:

```{r}
z_fit =
  lm_b(log_ozone ~ Solar.R + Wind + Temp + year_day,
       data = aq,
       prior_var_shape = a_and_b[1],
       prior_var_rate = a_and_b[2])
```

We can look again at the diagnostics
```{r}
plot(z_fit,
     type = "diagnostics")
```

We can look at the results through either the coef, print, or summary generics:
```{r}
summary(z_fit)
```
Note that the summary provides:

* **ROPE**: default values of region of practical equivalence (ROPE) based on principles of "ROPE = half a small effect size" are automatically computed (see [@kruschke2018rejecting] for a great discussion on default ROPE values),
* **Prob Dir**: Probability of direction, defined to be $\max(\Pr(\beta_j<0|y),\Pr(\beta_j>0|y))$, interpreted as *the confidence we have that we know the direction of the relationship between $y$ and $x$.*
* **BF favoring alternative**: Bayes factor comparing $\beta_j\neq0$ vs. $\beta_j=0$.  Alongside this we provide the **Interpretation** given by [@kass1995bayes].


We can also visualize our results by plotting the credible and prediction bands for each covariate.  When doing this, the other covariates not actively being plotted need to be fixed at some value.  Partial dependence plots get around this by averaging the predictions over all individuals in the data set, and can be visualized via:
```{r}
plot(z_fit,
     type = "pdp")
```
While PDPs are very useful when there are interaction terms, they don't, however, provide inference, and so often it is more useful to look at credible and prediction bands (dark blue are the credible bands, lighter blue are the prediction bands).  The user can either provide specific values, or else the algorithm will find the medoid observation in the training data and use those values.
```{r}
plot(z_fit,
     type = c("ci","pi"))
```
Note that any non-linearities are automatically accounted for.  For example:
```{r}
z_fit_2 =
  lm_b(log_ozone ~ Solar.R + I(Solar.R^2) + Wind + Temp + year_day,
       data = aq,
       prior_var_shape = a_and_b[1],
       prior_var_rate = a_and_b[2])

plot(z_fit_2,
     variable = "Solar.R",
     type = c("ci","pi"))
```

Multiple information criteria are available to compare the models:
```{r}
AIC(z_fit)
AIC(z_fit_2)

BIC(z_fit)
BIC(z_fit_2)

DIC(z_fit)
DIC(z_fit_2)

WAIC(z_fit)
WAIC(z_fit_2)
```

Finally, if there are quantities that can only be computed via posterior samples, one can use `get_posterior_draws` on the `lm_b` object.



# Generalized linear regression with `glm_b` {#sec-glm_b}


## Statistical Model
Generalized linear regression can also be considered the bread and butter of the practicing statistician.  Mathematically, the model is given by
$$
\begin{aligned}
  g(\mathbb{E}(y_i)) & = X_i\beta + \omega_i, \\
  y_i & \sim F(g^{-1}(X_i\beta + \omega_i)),
\end{aligned}
$$ {#eq-glinreg}
where $g()$ is the link function, $\omega_i$ is the offset, and $F$ is the distribution of $y$ (e.g., Poisson).

The prior used is 
$$
  \beta \sim N(\mu,V^{-1}).
$$

By default, one may use either a Zellner's g-prior or the same normal prior described above for `lm_b` when `prior = "conjugate"` (see @sec-lm_priors).

## Estimation
Unlike in the linear case, non-Gaussian distributed outcomes do not provide closed form solutions for the posterior distribution.  However, `bayesics` provides three fast ways to do inference.

### Variational Bayes (default)
Variational Bayes (VB) aims to find a distribution under some constraint that minimizes the Kullback-Leibler divergence between the true posterior and the constrained distribution.  There are two main types of VB: Mean Field and Fixed Form.  The former assumes independence between components, and tends towards underestimating uncertainty in the posterior.  `bayesics` uses the latter, where the approximating distribution is constrained to be a multivariate normal with unconstrained covariance matrix.  See [@salimans2013fixed] for details on this algorithm.

### Large sample approximation
The Bernstein-Von Mises theorem tells us that our posterior converges to a multivariate normal distribution as the sample size increases.  if `algorithm = "LSA"`, then this limiting distribution is used.  Note that this is the fastest algorithm available, and if the sample size is sufficiently large that the other two algorithms are slow, then the normal approximation is probably a pretty good one.

### Importance sampling
If there are concerns about the large sample approximation holding in the tails of the posterior, importance sampling can be used.  `bayesics` uses a multivariate $t$ distribution with 5 degrees of freedom (although this can be changed through the `proposal_df` argument) in order to better capture the tail behavior, and hence the bounds of the credible interval, ROPE, etc.  As described in `vignette("Introduction-to-bayesics",package="bayesics")`, `glm_b` automatically selects the correct number of samples required to obtain tight estimates on the credible interval bounds.


## Diagnostics
To evaluate the goodness-of-fit of the proposed model, `bayesics` implements Bayesian p-values, based on a function $T(y,\theta)$ of both the data $y$ and model parameters $\theta$.  For a given $T(\cdot,\cdot)$, Bayesian p-values are defined as
$$
  \Pr\Big(T(y_{new},\theta) , T(y_{obs},\theta)\Big|y_{obs}\Big),
$$
where $y_{obs}$ and $y_{new}$ are the observed and future/unobserved data.  Importantly, these values condition only on what is known ($y_{obs}$); in contrast, frequentist p-values (used for entirely different purposes) can be given as
$$
  \Pr(T(y_{new}) < T(y_{obs}) | \theta)
$$
and condition on what is unobserved ($\theta$).

The plot function in`bayesics` for `glm_b` objects uses Bayesian p-values, where the statistics $T$ is the deviance, i.e., $-2\log(\pi(y|\theta))$.  If the model is good, then data predicted by the model will have similar likelihood and thereby deviance as the observed data under the same model.  Thus, Bayesian p-values close to 0.5 are desireable, and values close to 0 or 1 indicate a poor model fit of the data.



## `glm_b` Example
As an example, we'll look at the breaks in yarn dataset:
```{r}
data("warpbreaks",
     package="datasets")
```
The outcome is the number of breaks per loom, and the predictors are type of wool and level of tension (both factor variables).


The default settings use VB to estimate the model using Zellner's g prior, with $g = n$.
```{r}
vb_fit = 
  glm_b(breaks ~ wool + tension,
        data = warpbreaks,
        family = poisson())
```

```{r}
print(
  summary(vb_fit),
  width = Inf)
```


Several other generics are available for both `lm_b` and `glm_b` objects (note that `credint` is the equivalent of `confint`).
```{r}
vb_fit
coef(vb_fit)
credint(vb_fit)
vcov(vb_fit)
SDratio(vb_fit)
```

We can also implement importance sampling or the asymptotic approximation and compare the results.
```{r}
is_fit = 
  glm_b(breaks ~ wool + tension,
        data = warpbreaks,
        family = poisson(),
        algorithm = "IS")
lsa_fit = 
  glm_b(breaks ~ wool + tension,
        data = warpbreaks,
        family = poisson(),
        algorithm = "LSA")
```


```{r}
cbind(credint(vb_fit),
      credint(is_fit),
      credint(lsa_fit)) |> 
  round(3)
```

We can assess the model adequacy via Bayesian p-values:
```{r}
plot(vb_fit,
     type = "dx")
```
From this, we see that the Bayesian p-value is 1, implying that the deviance for the predicted data is always smaller than that of the observed data, or equivalently has a larger likelihood than the observed data.  If this were a serious analysis, we would immediately stop and proceed to the non-parametric methods described below in @sec-np_glm_b.  However, for the purposes of describing the functionality of `bayesics`, we will continue as if this were a good fit.

As with `lm_b`, we can look at partial dependence plots, credible intervals/bands, and prediction intervals/bands.  The visualizations are given on the original scale, and as before, the darker blue corresponds to the credible intervals, and the lighter blue corresponds to prediction intervals.
```{r}
plot(vb_fit,
     type = c("ci","pi"))
```

We can use the same information criteria to compare models.
```{r}
# Fit the GLM with no wool
vb_fit_no_wool = 
  glm_b(breaks ~ tension,
        data = warpbreaks,
        family = poisson())
# Fit the GLM with no tension
vb_fit_no_tension = 
  glm_b(breaks ~ wool,
        data = warpbreaks,
        family = poisson())
# Fit the intercept only GLM
vb_fit_null_model = 
  glm_b(breaks ~ 1,
        data = warpbreaks,
        family = poisson())

# Collate the IC into a data.frame
collated_IC = 
  data.frame(IC = 
               c("AIC","BIC","DIC","WAIC"),
             Null =
               c(AIC(vb_fit_null_model),
                 BIC(vb_fit_null_model),
                 DIC(vb_fit_null_model)[1],
                 WAIC(vb_fit_null_model)[1]),
             `Wool only` = 
               c(AIC(vb_fit_no_tension),
                 BIC(vb_fit_no_tension),
                 DIC(vb_fit_no_tension)[1],
                 WAIC(vb_fit_no_tension)[1]),
             `Tension only` = 
               c(AIC(vb_fit_no_wool),
                 BIC(vb_fit_no_wool),
                 DIC(vb_fit_no_wool)[1],
                 WAIC(vb_fit_no_wool)[1]),
             `Full` = 
               c(AIC(vb_fit),
                 BIC(vb_fit),
                 DIC(vb_fit)[1],
                 WAIC(vb_fit)[1])
  )

knitr::kable(collated_IC)
```


# Non-parametric general Bayesian inference for GLMs with `np_glm_b` {#sec-np_glm_b}

## Background
Suppose we do not believe our model is correctly specified ("All models are wrong$\ldots$").  Then in that case, we must rethink what our parameters mean, and how to do inference on them.  [@lyddon2019general] provide a clear description of what the estimand is, and how to go about making inference on it.  Below is a very brief overview; we recommend the reader to read Lyddon et al.'s manuscript in its entirety.

First, it is perhaps obvious yet important to state that the estimand we care about should revolve around the population, not the sample.  Second, it should be reasonable to be able to provide some loss function between an individual and the model parameters (e.g., $(y_i - X_i\beta)$ for linear regression).  Third, if we were able to fully describe the population distribution, then we would select the model parameter which minimizes the loss averaged over the population distribution.  For example, if we were fitting a LOESS model, the "truth"/estimand that we would be aiming for with our finite sample estimation would be the LOESS fit that would be obtained were we to create the fit using the entire population.  

More formally, if we have a parameter $\theta\in\Theta$ and individual observations $y_i\in{\cal Y}$, let $\ell:(\Theta,{\cal Y})\mapsto\Re$ denote our loss function, let $F$ denote the population distribution of the $y_i$'s, then our estimand is $\theta(F)$, denoted as such to emphasize the fact that it is a function of the population distribution of $y$, and given by
$$
  \theta(F) := \underset{\theta\in\Theta}{\text{argmin}}\int_{{\cal Y}}\ell(\theta,y)dF(y).
$$
What is hopefully clear from this is that there is a one-to-one correspondence between having a prior on $\theta(F)$ and a prior on $F$.  And with this realization, Lyddon et al. brought in the Bayesian bootstrap, a non-parametric approach to making inference on the population distribution.  **Hence to use this approach, one does not need to specify any prior distribution, nor does one need to assume that the model is correctly specified.**  

`np_glm_b` by default uses the self-information loss function, which equals the negative log likelihood function.  Also available is the generalized least squares, i.e., $\frac{(y_i - \mathbb{E}(y_i|\theta))^2}{\text{Var}(y_i|\theta)}$, where the moments are under the typical GLM; however, this yields highly biased estimates in most cases.  Additionally, user-supplied loss functions can be implemented.


## `np-glm_b` Example
Now let's see how to implement it in `bayesics`. Let's revisit the breaks in yarn dataset, since clearly from the Bayesian p-value we could see that the Poisson GLM was not the correct model.  Instead of using `glm_b`, we will use the same syntax but use `np_glm_b` instead.   Of note is that there are two ways to do inference.  First, the Bayesian bootstrap can be computed directly, although this is computationally expensive. Because of this, it is recommended to use   Second, there is a large sample approximation that can be used here, and which is the default.
```{r}
np_fit = 
  np_glm_b(breaks ~ wool + tension,
           data = warpbreaks,
           family = poisson())
# Not run:
# plan(multisession, workers = 10)
np_fit_bs = 
  np_glm_b(breaks ~ wool + tension,
           data = warpbreaks,
           family = poisson(),
           n_draws = 500,
           ask_before_full_sampling = FALSE)
```
We can compare the results between the large sample and the exact finite sample inferential methods:
```{r}
np_fit
np_fit_bs
```
Despite there being only `r nrow(warpbreaks)` observations, the large sample approximation is nearly identical to the full bootstrap approach.

The following generics work for `np_glm_b` objects:
```{r}
print(
  summary(np_fit),
  width = Inf)
coef(np_fit)
credint(np_fit)
vcov(np_fit)
```

The `vcov` is particularly useful for contrasts.  For example, if we want to know what is the posterior probability that the rate of breaks is higher for medium tension looms than for high tension looms, our contrast is $\beta_{\text{tension:mediun}} - \beta_{\text{tension:high}}$.  From our fitted object, we can make inference on this contrast via:
```{r}
# look at names of the coefficients:
names(coef(np_fit))

# Create the contrast vector
contrast_vector = 
  c(0, 0, 1, -1)

# Compute the point estimate of the contrast
contrast_hat = 
  drop(
    contrast_vector %*% coef(np_fit)
  )

# Compute the standard error of the contrast
contrast_se = 
  drop(
    contrast_vector %*% vcov(np_fit) %*% contrast_vector
  ) |> 
  sqrt()

# Compute the 95% interval estimate of the contrast
contrast_ci = 
  contrast_hat + c(-1,1) * qnorm(0.975) * contrast_se

paste0("Estimate: ",
       round(contrast_hat,3),
       "; 95% CI: (",
       paste(round(contrast_ci,3),collapse=","),
       ")\n") |> 
  cat()
```

In addition, we have the plot generic.  There are no diagnostics, since we are actually assuming the model is mis-specified, nor can there be prediction intervals since we are not assuming a true data generating process, but we can still look at the PDPs and credible intervals/bands:
```{r}
plot(np_fit)
```















<!-- Use occupationalStatus for independence_b example. -->
<!-- Use infert for case_control example. -->